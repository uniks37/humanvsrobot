{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing everything\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "import collections.abc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import types\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import auc, confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_curve\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the files read\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "bids_df = pd.read_csv('dataset/bids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Length:%d' %len(train_df))\n",
    "print('Test Length:%d' %len(test_df))\n",
    "print('Bids Length:%d' %len(bids_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting column info\n",
    "print('Train columns: %s\\n' %(train_df.columns.values))\n",
    "print('Test columns: %s\\n' %(test_df.columns.values))\n",
    "print('Bids columns: %s\\n' %(bids_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the data difference\n",
    "sns.countplot(x='outcome', data=train_df)\n",
    "print(collections.Counter(train_df['outcome']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding the difference between top 10 bidding nations\n",
    "top_bidding_nations = collections.Counter(bids_df['country']).most_common(10)\n",
    "top_df = pd.DataFrame(top_bidding_nations, columns=['country', 'count'])\n",
    "sns.barplot(x='country', y='count', data=top_df)\n",
    "print(top_bidding_nations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Morphing into metadf\n",
    "meta_train_df = []\n",
    "meta_test_df = []\n",
    "cnt = 0\n",
    "len_bids = len(bids_df)\n",
    "#Fetching pre-existing metadata files as computation takes a lot of time\n",
    "try:\n",
    "    print('Fetching already existing files')\n",
    "    meta_train_df = pd.read_csv('dataset/meta_train.csv')\n",
    "    meta_test_df = pd.read_csv('dataset/meta_test.csv')\n",
    "#If files don't exist already, create and write the data\n",
    "except FileNotFoundError as fnfe:\n",
    "    train_bidders = list(train_df['bidder_id'])\n",
    "    test_bidders = list(test_df['bidder_id'])\n",
    "    for bidder_bid in bids_df.values:\n",
    "        if bidder_bid[1] in train_bidders:\n",
    "            meta_train_df.append(np.concatenate((bidder_bid, (train_df.loc[train_df['bidder_id'] == bidder_bid[1]]).values[0][1:]), axis=0))\n",
    "        elif bidder_bid[1] in test_bidders:\n",
    "            meta_test_df.append(np.concatenate((bidder_bid, (test_df.loc[test_df['bidder_id'] == bidder_bid[1]]).values[0][1:]), axis=0))\n",
    "        cnt+=1\n",
    "        sys.stdout.write('\\rRecords done:%.4f'%(cnt/len_bids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to dfs\n",
    "meta_train_df = pd.DataFrame(meta_train_df, columns=np.concatenate((bids_df.columns, train_df.columns[1:]), axis=0))\n",
    "meta_test_df = pd.DataFrame(meta_test_df, columns=np.concatenate((bids_df.columns, test_df.columns[1:]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write dfs to file for saving computations if things go south\n",
    "meta_train_df.to_csv('dataset/meta_train.csv')\n",
    "meta_test_df.to_csv('dataset/meta_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting train data in order to easy readability access\n",
    "meta_train_df = meta_train_df.sort_values(['bidder_id', 'merchandise', 'time'],  ascending=[1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating bins in order to plot binwise distribution\n",
    "sns.set(); np.random.seed(32)\n",
    "x = list((meta_train_df.loc[meta_train_df['outcome'] == 1.0]).groupby('bidder_id').size())\n",
    "highest_pow = math.ceil(math.log(max(x), 2))\n",
    "bins = []\n",
    "[bins.append((2**(k-1), 2**(k)-1)) for k in range(1, highest_pow)]\n",
    "changed_ds = []\n",
    "for i in x:\n",
    "    [changed_ds.append(k) for k in range(len(bins)) if bins[k][0] <= i <= bins[k][1]]\n",
    "#Plot graph binwise count of bidders\n",
    "sns.countplot(changed_ds)\n",
    "print(bins)\n",
    "print(list(collections.Counter(changed_ds).most_common()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get unique train and test data\n",
    "unique_train_bidder = meta_train_df.bidder_id.unique()\n",
    "unique_test_bidder = meta_test_df.bidder_id.unique()\n",
    "\n",
    "print('Considerable training data: %d'%len(unique_train_bidder))\n",
    "print('Considerable testing data: %d'%len(unique_test_bidder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to store bidder specific features\n",
    "class BidderData:\n",
    "    def __init__(self, bidder_id, bid_ids, countries, urls, auctions, merchandise, devices, times, ips, outcome=None):\n",
    "        self.bidder_id = bidder_id #Bidder_id\n",
    "        self.bid_ids = list(bid_ids) #Bid_id\n",
    "        self.countries = list(countries) #countries\n",
    "        self.urls = list(urls) #URLs\n",
    "        self.auctions = list(auctions) #auctions\n",
    "        self.merchandise = list(merchandise) #merchandise\n",
    "        self.devices = list(devices) #devices\n",
    "        self.times = list(times) #times\n",
    "        self.ips = list(ips) #ips\n",
    "        self.lasttmbids = 0 #max bids placed in 20 minutes\n",
    "        self.lastthbids = 0 #max bids placed in 2 hours\n",
    "        if not outcome == None:\n",
    "            self.outcome = outcome #outcome target lable\n",
    "        self.__getRepeatedTimes() #Unique timestamps\n",
    "        self.__getMerchandiseUnique() #Unique merchandise\n",
    "        self.__getDevicesUnique() #Unique devices\n",
    "        self.__getURLsUnique() #Unique urls\n",
    "        self.__getRatioNativeCountry() #Ratio of bids placed from native country\n",
    "        self.__getRatioURL() #Ratio of bids placed from main url\n",
    "        self.__getRatioDevice() #Ratio of bids placed from main device\n",
    "        self.__medConsecutiveBidsTime() #time of placing consecutive bids\n",
    "        self.__getIPUnique() #Unique Ips\n",
    "        self.__getAvgBidsPerAuction() #bids placed per auction\n",
    "        self.__getLastTMBids() \n",
    "        self.__getLastTHBids() \n",
    "        self.__medConsecutiveBidsTime()\n",
    "        self.__len_attrib()\n",
    "    \n",
    "    def __len_attrib(self):\n",
    "        self.total_bids = len(list(self.bid_ids))\n",
    "\n",
    "    def __getRepeatedTimes(self):\n",
    "        self.repeated_times = len(self.times) - len(pd.unique(self.times))\n",
    "    def __getMerchandiseUnique(self):\n",
    "        self.merchandise_unique = len(pd.unique(self.merchandise))\n",
    "    def __getDevicesUnique(self):\n",
    "        self.devices_unique = len(pd.unique(self.devices))\n",
    "    def __getURLsUnique(self):\n",
    "        self.urls_unique = len(pd.unique(self.urls))\n",
    "    def __getIPUnique(self):\n",
    "        self.ips_unique = len(pd.unique(self.ips))\n",
    "    \n",
    "    def __getRatioNativeCountry(self):\n",
    "        if len(self.countries) > 0:\n",
    "            self.ratioNC = collections.Counter(self.countries).most_common(1)[0][1]/len(self.countries)\n",
    "        else:\n",
    "            self.ratioNC = 1\n",
    "    def __getRatioURL(self):\n",
    "        if len(self.urls) > 0:\n",
    "            self.ratioURL = collections.Counter(self.urls).most_common(1)[0][1]/len(self.urls)\n",
    "        else:\n",
    "            self.ratioURL = 1\n",
    "    def __getRatioDevice(self):\n",
    "        if len(self.devices) > 0:\n",
    "            self.ratioDevices = collections.Counter(self.urls).most_common(1)[0][1]/len(self.devices)\n",
    "        else:\n",
    "            self.ratioDevices = 0\n",
    "    \n",
    "    def __getAvgBidsPerAuction(self):\n",
    "        if len(self.bid_ids) > 0 and len(self.auctions) > 0:\n",
    "            self.avg_bid_auc = len(pd.unique(self.bid_ids))/len(pd.unique(self.auctions))\n",
    "        else:\n",
    "            self.avg_bid_auc = 0\n",
    "    \n",
    "    def __medConsecutiveBidsTime(self):\n",
    "        srt_time_split = sorted(self.times, reverse=True)\n",
    "        if len(srt_time_split) > 1:\n",
    "            self.fastest_consec_bid = np.min([(srt_time_split[x]-srt_time_split[x+1]) for x in range(len(srt_time_split[:-1]))])\n",
    "            self.cons_bids_time = np.median([(srt_time_split[x]-srt_time_split[x+1]) for x in range(len(srt_time_split[:-1]))])\n",
    "        else:\n",
    "            self.fastest_consec_bid = sys.maxsize\n",
    "            self.cons_bids_time = sys.maxsize\n",
    "    \n",
    "    def __getLastTMBids(self):\n",
    "        sorted_time = sorted(self.times, reverse=True)\n",
    "        max_d = 0\n",
    "        for i in range(len(sorted_time)):\n",
    "            d = 0\n",
    "            for j in range(i, len(sorted_time)):\n",
    "                if sorted_time[i] - sorted_time[j] <= 1200000:\n",
    "                    d+=1\n",
    "                    if d > max_d:\n",
    "                        max_d = d\n",
    "                else:\n",
    "                    break\n",
    "        self.lasttmbids = max_d\n",
    "        \n",
    "    def __getLastTHBids(self):\n",
    "        sorted_time = sorted(self.times, reverse=True)\n",
    "        max_d = 0\n",
    "        for i in range(len(sorted_time)):\n",
    "            d = 0\n",
    "            for j in range(i, len(sorted_time)):\n",
    "                if sorted_time[i] - sorted_time[j] <= 7200000:\n",
    "                    d+=1\n",
    "                    if d > max_d:\n",
    "                        max_d = d\n",
    "                else:\n",
    "                    break\n",
    "        self.lasthbids = max_d\n",
    "        \n",
    "    def to_dict(self):\n",
    "        repr_dict = {}\n",
    "        for k, v in self.__dict__.items():\n",
    "            if type([]) != type(v) and type(np.asarray([])) != type(v):\n",
    "                repr_dict[k] = v\n",
    "        return repr_dict\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Bidder_id: %s, Total bids: %d' %(self.bidder_id, self.total_bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare training data\n",
    "train_collection = {}\n",
    "cnt = 0\n",
    "err_cnt = 0\n",
    "for utb in train_df['bidder_id'].values:\n",
    "    #If we have bidder data\n",
    "    if utb in unique_train_bidder:\n",
    "        temp_bidder_meta = meta_train_df.loc[meta_train_df['bidder_id'] == utb]\n",
    "        train_collection[utb] = BidderData(utb, temp_bidder_meta['bid_id'], temp_bidder_meta['country'], temp_bidder_meta['url'], temp_bidder_meta['auction'], temp_bidder_meta['merchandise'], temp_bidder_meta['device'], temp_bidder_meta['time'], temp_bidder_meta['ip'], outcome = list(temp_bidder_meta['outcome'])[0])\n",
    "        cnt+=1\n",
    "    #If we have no bidder data, initialize\n",
    "    else:\n",
    "        train_collection[utb] = BidderData(utb, [], [], [], [], [], [], [], [], outcome = 0)\n",
    "        err_cnt += 1\n",
    "    sys.stdout.write('\\r%d : %d - %s' %(cnt, err_cnt, train_collection[utb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating final training set\n",
    "training_df_final = pd.DataFrame.from_records([dfs.to_dict() for dfs in train_collection.values() if not (dfs.total_bids == 1 and dfs.outcome == 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training features are: %s'%training_df_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train data and labels\n",
    "training_df_fl = training_df_final[[col for col in training_df_final if col not in ['outcome', 'bidder_id']]]\n",
    "training_df_flabel = training_df_final[[col for col in training_df_final if col in ['outcome']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying neighborhood cleaning rule and preparing 1st phase model data\n",
    "ncr = NeighbourhoodCleaningRule(n_neighbors=15, random_state=32, ratio={0:0.5})\n",
    "training_df_X, training_df_y = ncr.fit_resample(training_df_fl, training_df_flabel.values.reshape(1, -1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating class for containing different model executions\n",
    "class ClassifierContainer:\n",
    "    def __init__(self, model, training_X, training_y, measuring_parameter='auc'):\n",
    "        self.model = model\n",
    "        self.training_X = training_X\n",
    "        self.training_y = training_y\n",
    "        self.measuring_parameter = measuring_parameter\n",
    "    \n",
    "    #Predicting results\n",
    "    def predict_get_results(self, n_splits):\n",
    "        result_list = []\n",
    "        #Kfold cross val\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "        for train_indices, validation_indices in kf.split(self.training_X):\n",
    "            X_train, X_valid = self.training_X[train_indices], self.training_X[validation_indices]\n",
    "            y_train, y_valid = self.training_y[train_indices], self.training_y[validation_indices]\n",
    "            self.model.fit(X_train, y_train)\n",
    "            pred_y = self.model.predict(X_valid)\n",
    "            #Measures\n",
    "            cm = confusion_matrix(y_valid, pred_y)\n",
    "            acs = accuracy_score(y_valid, pred_y)\n",
    "            ps = precision_score(y_valid, pred_y)\n",
    "            rs = recall_score(y_valid, pred_y)\n",
    "            f1_s = f1_score(y_valid, pred_y)\n",
    "            fpr, tpr, thresholds = roc_curve(y_valid, pred_y)\n",
    "            aucs = auc(fpr, tpr)\n",
    "            result = {'pred_y':pred_y, 'cm':cm, 'acs':acs, 'ps':ps, 'rs':rs, 'f1_s':f1_s, 'auc': aucs, 'model':copy.deepcopy(self.model)}\n",
    "            result_list.append(result)\n",
    "        self.results = None\n",
    "        for result in result_list:\n",
    "            if not self.measuring_parameter in result:\n",
    "                self.measuring_parameter = 'auc'\n",
    "            if self.results == None or self.results[self.measuring_parameter] < result[self.measuring_parameter]:\n",
    "                self.pred_y = result['pred_y']\n",
    "                del result['pred_y']\n",
    "                self.results = result\n",
    "                self.best_model = result['model']\n",
    "                \n",
    "        return self.results\n",
    "    \n",
    "    #Get best model\n",
    "    def get_Best_Instance(self):\n",
    "        return self.best_model\n",
    "    \n",
    "    #Return prediction\n",
    "    def get_prediction(self):\n",
    "        return self.pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Booster\n",
    "xbg_container = ClassifierContainer(GradientBoostingClassifier(), training_df_X, training_df_y)\n",
    "print(xbg_container.predict_get_results(n_splits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "adb_container = ClassifierContainer(AdaBoostClassifier(n_estimators=1500), training_df_X, training_df_y)\n",
    "print(adb_container.predict_get_results(n_splits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "rfc_container = ClassifierContainer(RandomForestClassifier(n_estimators=1500), training_df_X, training_df_y)\n",
    "print(rfc_container.predict_get_results(n_splits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "svm_container = ClassifierContainer(svm.SVC(gamma='scale'), training_df_X, training_df_y)\n",
    "print(svm_container.predict_get_results(n_splits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is located on outcome\n",
    "x_loc = pd.DataFrame(training_df_flabel.values.reshape(1, -1)[0], columns=['outcome'])\n",
    "x_loc = x_loc.loc[x_loc['outcome']==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Purify and prepare data\n",
    "bi_info = meta_train_df.loc[meta_train_df['bidder_id'] == unique_train_bidder[331]]\n",
    "country_list = list(bi_info.to_dict()['country'].values())\n",
    "for cnt in country_list:\n",
    "    if type(cnt) == type(float) and math.isnan(cnt):\n",
    "        print(collections.Counter(list(bids_df.loc[bids_df['ip'].str.startswith(str(bi_info['ip'].values[0])[:4]), 'country'])).most_common()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null countries and replace them with nearest ips\n",
    "null_countries = []\n",
    "for tr_bd in bids_df.values:\n",
    "    cnt = 0\n",
    "    for x in tr_bd:\n",
    "        if pd.isnull(x):\n",
    "            null_countries.append((tr_bd, cnt))\n",
    "        cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number countries with NaN values: %s'%len(null_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get custom model split\n",
    "def get_custom_split(training_df_X, training_df_y, n_splits = 5):\n",
    "    #Train-Validation bot ids\n",
    "    training_bot_ind = (training_df_y.loc[training_df_y['outcome'] == 1.0]).index.values\n",
    "    validation_bot_ind = np.random.choice(training_bot_ind, size = int(0.3*len(training_bot_ind)), replace=False)\n",
    "    training_bot_ind = np.setdiff1d(training_bot_ind, validation_bot_ind)\n",
    "    training_ind_arr = []\n",
    "    #Train-Validation human ids\n",
    "    for i in range(n_splits):\n",
    "        training_hum_ind = (training_df_y.loc[training_df_y['outcome'] == 0.0]).index.values\n",
    "        validation_hum_ind = np.random.choice(training_hum_ind, size = int(0.3*len(training_hum_ind)), replace=False)\n",
    "        training_hum_ind = np.setdiff1d(training_hum_ind, validation_hum_ind)\n",
    "        training_ind = np.append(np.random.choice(training_hum_ind, size=int(len(training_hum_ind)/1.9)), training_bot_ind)\n",
    "        np.random.shuffle(training_ind)\n",
    "        training_ind_arr.append(training_ind)\n",
    "    validation_ind = np.append(validation_bot_ind, validation_hum_ind)\n",
    "    np.random.shuffle(validation_ind)\n",
    "    return [training_df_X.iloc[training_ind_i] for training_ind_i in training_ind_arr], [training_df_y.iloc[training_ind_i] for training_ind_i in training_ind_arr], training_df_X.iloc[validation_ind], training_df_y.iloc[validation_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate train-validation sets\n",
    "train_df_X_set, train_df_y_set, validation_df_X, validation_df_y = get_custom_split(training_df_fl, training_df_flabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our model - Ensemble of ensemble\n",
    "results = {'cm':[], 'acs':[],'ps':[], 'rs':[], 'f1_s':[], 'auc':[]}\n",
    "for i in range(len(train_df_X_set)):\n",
    "    train_df_y_transpose = train_df_y_set[i].values.reshape(1,-1)[0]\n",
    "    ncr = NeighbourhoodCleaningRule(n_neighbors=1, random_state=32)\n",
    "    train_df_X_i, train_df_y_i = ncr.fit_resample(train_df_X_set[i], train_df_y_transpose)\n",
    "    rfc1_y = ((RandomForestClassifier(n_estimators=1500)).fit(train_df_X_i, train_df_y_i)).predict(validation_df_X)\n",
    "    xgb1_y = ((GradientBoostingClassifier(n_estimators=1500)).fit(train_df_X_i, train_df_y_i)).predict(validation_df_X)\n",
    "    adb1_y = ((AdaBoostClassifier(n_estimators=1500, random_state=42, learning_rate=0.098)).fit(train_df_X_i, train_df_y_i)).predict(validation_df_X)\n",
    "    svm1_y = ((svm.SVC(gamma='scale')).fit(train_df_X_set[i], train_df_y_set[i])).predict(validation_df_X)\n",
    "    rfc2_y = ((RandomForestClassifier(n_estimators=1500)).fit(train_df_X_set[i], train_df_y_set[i])).predict(validation_df_X)\n",
    "    xgb2_y = ((GradientBoostingClassifier(n_estimators=1500)).fit(train_df_X_set[i], train_df_y_set[i])).predict(validation_df_X)\n",
    "    adb2_y = ((AdaBoostClassifier(n_estimators=1500, random_state=42, learning_rate=0.098)).fit(train_df_X_set[i], train_df_y_set[i])).predict(validation_df_X)\n",
    "    \n",
    "    gen_y = []\n",
    "    for i in range(len(validation_df_y['outcome'])):\n",
    "        f1 = (0.48*svm1_y[i])+(0.27*rfc1_y[i])+(0.25*adb1_y[i])\n",
    "        f2 = (0.3*rfc2_y[i])+(0.35*xgb2_y[i])+(0.35*adb2_y[i])\n",
    "        gen_y.append(round(max(f1, f2)))\n",
    "    results['cm'].append(confusion_matrix(gen_y, validation_df_y['outcome']))\n",
    "    results['acs'].append(accuracy_score(gen_y, validation_df_y['outcome']))\n",
    "    results['ps'].append(precision_score(gen_y, validation_df_y['outcome']))\n",
    "    results['rs'].append(recall_score(gen_y, validation_df_y['outcome']))\n",
    "    results['f1_s'].append(f1_score(gen_y, validation_df_y['outcome']))\n",
    "    fpr, tpr, thresholds = roc_curve(gen_y, validation_df_y['outcome'])\n",
    "    results['auc'].append(auc(fpr, tpr))\n",
    "results_custom_pd = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputting report\n",
    "print(results_custom_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare xbgs\n",
    "results = {}\n",
    "xbg_container_0 = ClassifierContainer(GradientBoostingClassifier(), training_df_X, training_df_y)\n",
    "results['Vanilla'] = (xbg_container_0.predict_get_results(n_splits=4))['auc']\n",
    "xbg_container_1 = ClassifierContainer(GradientBoostingClassifier(max_features=5), training_df_X, training_df_y)\n",
    "results['m_feat 5'] = (xbg_container_1.predict_get_results(n_splits=4))['auc']\n",
    "xbg_container_2 = ClassifierContainer(GradientBoostingClassifier(learning_rate=0.01), training_df_X, training_df_y)\n",
    "results['l_rate 0.01'] = (xbg_container_2.predict_get_results(n_splits=4))['auc']\n",
    "xbg_container_3 = ClassifierContainer(GradientBoostingClassifier(max_depth=15), training_df_X, training_df_y)\n",
    "results['m_depth 15'] = (xbg_container_3.predict_get_results(n_splits=4))['auc']\n",
    "xbg_container_4 = ClassifierContainer(GradientBoostingClassifier(learning_rate=0.15, max_features=10), training_df_X, training_df_y)\n",
    "results['l_rate 0.15\\nm_feat 10'] = (xbg_container_4.predict_get_results(n_splits=4))['auc']\n",
    "\n",
    "res_xbg_df = pd.DataFrame([(k, v) for k, v in results.items()], columns=['Title', 'AUC'])\n",
    "print(res_xbg_df)\n",
    "sns.barplot(x='Title', y='AUC', data=res_xbg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare adaboost classifier\n",
    "results = {}\n",
    "abd_container_0 = ClassifierContainer(AdaBoostClassifier(), training_df_X, training_df_y)\n",
    "results['Vanilla'] = (abd_container_0.predict_get_results(n_splits=4))['auc']\n",
    "abd_container_1 = ClassifierContainer(AdaBoostClassifier(n_estimators=1000), training_df_X, training_df_y)\n",
    "results['n_estim 5'] = (abd_container_1.predict_get_results(n_splits=4))['auc']\n",
    "abd_container_2 = ClassifierContainer(AdaBoostClassifier(learning_rate=0.01), training_df_X, training_df_y)\n",
    "results['l_rate 0.01'] = (abd_container_2.predict_get_results(n_splits=4))['auc']\n",
    "abd_container_3 = ClassifierContainer(AdaBoostClassifier(random_state=15), training_df_X, training_df_y)\n",
    "results['m_depth 15'] = (abd_container_3.predict_get_results(n_splits=4))['auc']\n",
    "abd_container_4 = ClassifierContainer(AdaBoostClassifier(learning_rate=0.15, n_estimators=1500), training_df_X, training_df_y)\n",
    "results['l_rate 0.15\\nn_estim 1500'] = (abd_container_4.predict_get_results(n_splits=4))['auc']\n",
    "\n",
    "res_abd_df = pd.DataFrame([(k, v) for k, v in results.items()], columns=['Title', 'AUC'])\n",
    "print(res_abd_df)\n",
    "sns.barplot(x='Title', y='AUC', data=res_abd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare randomforest\n",
    "results = {}\n",
    "rfc_container_0 = ClassifierContainer(RandomForestClassifier(), training_df_X, training_df_y)\n",
    "results['Vanilla'] = (rfc_container_0.predict_get_results(n_splits=4))['auc']\n",
    "rfc_container_1 = ClassifierContainer(RandomForestClassifier(max_features=5), training_df_X, training_df_y)\n",
    "results['m_feat 5'] = (rfc_container_1.predict_get_results(n_splits=4))['auc']\n",
    "rfc_container_2 = ClassifierContainer(RandomForestClassifier(max_depth=10), training_df_X, training_df_y)\n",
    "results['l_depth 10'] = (rfc_container_2.predict_get_results(n_splits=4))['auc']\n",
    "rfc_container_3 = ClassifierContainer(RandomForestClassifier(class_weight={0.0:0.2}), training_df_X, training_df_y)\n",
    "results['c_weight 0.1'] = (rfc_container_3.predict_get_results(n_splits=4))['auc']\n",
    "rfc_container_4 = ClassifierContainer(RandomForestClassifier(max_features=10, max_depth=10), training_df_X, training_df_y)\n",
    "results['m_feat 10\\nm_depth 10'] = (rfc_container_4.predict_get_results(n_splits=4))['auc']\n",
    "\n",
    "res_rfc_df = pd.DataFrame([(k, v) for k, v in results.items()], columns=['Title', 'AUC'])\n",
    "print(res_rfc_df)\n",
    "sns.barplot(x='Title', y='AUC', data=res_rfc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featwise stats\n",
    "results = {}\n",
    "for col in range(training_df_X.shape[1]):\n",
    "    xbg_container_0 = ClassifierContainer(GradientBoostingClassifier(), training_df_X[:,col].reshape(-1, 1), training_df_y)\n",
    "    results[(training_df_fl.columns)[col]] = (xbg_container_0.predict_get_results(n_splits=4))['auc']\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Feature and AUC\n",
    "results_out = [(k, v) for k,v in results.items()]\n",
    "results_out.sort(key=lambda x: x[1], reverse=True)\n",
    "sns.barplot(x='Feature', y='AUC', data=pd.DataFrame(results_out[:4], columns=['Feature', 'AUC']))\n",
    "print(results_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test prediction\n",
    "test_collection = {}\n",
    "cnt = 0\n",
    "err_cnt = 0\n",
    "for utb in test_df['bidder_id'].values:\n",
    "    if utb in unique_test_bidder:\n",
    "        temp_bidder_meta = meta_test_df.loc[meta_test_df['bidder_id'] == utb]\n",
    "        test_collection[utb] = BidderData(utb, temp_bidder_meta['bid_id'], temp_bidder_meta['country'], temp_bidder_meta['url'], temp_bidder_meta['auction'], temp_bidder_meta['merchandise'], temp_bidder_meta['device'], temp_bidder_meta['time'], temp_bidder_meta['ip'])\n",
    "        cnt+=1\n",
    "    else:\n",
    "        test_collection[utb] = BidderData(utb, [], [], [], [], [], [], [], [])\n",
    "        err_cnt += 1\n",
    "    sys.stdout.write('\\r%d : %d - %s' %(cnt, err_cnt, test_collection[utb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df_final = pd.DataFrame.from_records([dfs.to_dict() for dfs in test_collection.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df_final = testing_df_final[[col for col in testing_df_final if col not in ['bidder_id']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/format.txt', 'w+') as writable_file:\n",
    "    adb_container = ClassifierContainer(GradientBoostingClassifier(), training_df_X, training_df_y)\n",
    "    prediction_test = adb_container.predict_get_results(n_splits=4)\n",
    "    test_preds = prediction_test['model'].predict(testing_df_final)\n",
    "    for a in test_preds:\n",
    "        writable_file.write('%d\\n'%a)\n",
    "    writable_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
